{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63cbf3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总组数: 1605 | 抽检组数: 321 | subset条数: 1605 | rest条数: 6420\n",
      "Subset scoring: 30%"
     ]
    },
    {
     "ename": "ServerError",
     "evalue": "503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mServerError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 150\u001b[0m\n\u001b[0;32m    148\u001b[0m b \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mSynthetic\n\u001b[0;32m    149\u001b[0m s_gpt    \u001b[38;5;241m=\u001b[39m score_gpt(a, b)\n\u001b[1;32m--> 150\u001b[0m s_gemini \u001b[38;5;241m=\u001b[39m score_gemini(a, b)\n\u001b[0;32m    151\u001b[0m s_bert   \u001b[38;5;241m=\u001b[39m score_bert(a, b)\n\u001b[0;32m    152\u001b[0m sub_rows\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpair_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: r\u001b[38;5;241m.\u001b[39mpair_id,\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal\u001b[39m\u001b[38;5;124m\"\u001b[39m: a,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_clinicalbert\u001b[39m\u001b[38;5;124m\"\u001b[39m: s_bert\n\u001b[0;32m    162\u001b[0m })\n",
      "Cell \u001b[1;32mIn[1], line 115\u001b[0m, in \u001b[0;36mscore_gemini\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore_gemini\u001b[39m(a: \u001b[38;5;28mstr\u001b[39m, b: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m    114\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m SCORE_PROMPT\u001b[38;5;241m.\u001b[39mformat(A\u001b[38;5;241m=\u001b[39ma, B\u001b[38;5;241m=\u001b[39mb)\n\u001b[1;32m--> 115\u001b[0m     response \u001b[38;5;241m=\u001b[39m gem_client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content(model\u001b[38;5;241m=\u001b[39mGEM_MODEL, contents\u001b[38;5;241m=\u001b[39mprompt)\n\u001b[0;32m    116\u001b[0m     out \u001b[38;5;241m=\u001b[39m (response\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m extract_score(out)\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\google\\genai\\models.py:6138\u001b[0m, in \u001b[0;36mModels.generate_content\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   6136\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   6137\u001b[0m   i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 6138\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content(\n\u001b[0;32m   6139\u001b[0m       model\u001b[38;5;241m=\u001b[39mmodel, contents\u001b[38;5;241m=\u001b[39mcontents, config\u001b[38;5;241m=\u001b[39mparsed_config\n\u001b[0;32m   6140\u001b[0m   )\n\u001b[0;32m   6141\u001b[0m   logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAFC remote call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is done.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   6142\u001b[0m   remaining_remote_calls_afc \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\google\\genai\\models.py:4959\u001b[0m, in \u001b[0;36mModels._generate_content\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   4956\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mconvert_to_dict(request_dict)\n\u001b[0;32m   4957\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mencode_unserializable_types(request_dict)\n\u001b[1;32m-> 4959\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m   4960\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m, path, request_dict, http_options\n\u001b[0;32m   4961\u001b[0m )\n\u001b[0;32m   4963\u001b[0m response_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;28;01melse\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mbody)\n\u001b[0;32m   4965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mvertexai:\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\google\\genai\\_api_client.py:1266\u001b[0m, in \u001b[0;36mBaseApiClient.request\u001b[1;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m   1257\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1258\u001b[0m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1261\u001b[0m     http_options: Optional[HttpOptionsOrDict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SdkHttpResponse:\n\u001b[0;32m   1263\u001b[0m   http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[0;32m   1264\u001b[0m       http_method, path, request_dict, http_options\n\u001b[0;32m   1265\u001b[0m   )\n\u001b[1;32m-> 1266\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(http_request, http_options, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1267\u001b[0m   response_body \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1268\u001b[0m       response\u001b[38;5;241m.\u001b[39mresponse_stream[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mresponse_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1269\u001b[0m   )\n\u001b[0;32m   1270\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders, body\u001b[38;5;241m=\u001b[39mresponse_body)\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\google\\genai\\_api_client.py:1086\u001b[0m, in \u001b[0;36mBaseApiClient._request\u001b[1;34m(self, http_request, http_options, stream)\u001b[0m\n\u001b[0;32m   1083\u001b[0m     retry \u001b[38;5;241m=\u001b[39m tenacity\u001b[38;5;241m.\u001b[39mRetrying(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mretry_kwargs)\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[1;32m-> 1086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_once, http_request, stream)\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    323\u001b[0m     retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 325\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m retry_exc\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait:\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\google\\genai\\_api_client.py:1063\u001b[0m, in \u001b[0;36mBaseApiClient._request_once\u001b[1;34m(self, http_request, stream)\u001b[0m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1056\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpx_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m   1057\u001b[0m       method\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m   1058\u001b[0m       url\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1061\u001b[0m       timeout\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[0;32m   1062\u001b[0m   )\n\u001b[1;32m-> 1063\u001b[0m   errors\u001b[38;5;241m.\u001b[39mAPIError\u001b[38;5;241m.\u001b[39mraise_for_response(response)\n\u001b[0;32m   1064\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[0;32m   1065\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[0;32m   1066\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\google\\genai\\errors.py:107\u001b[0m, in \u001b[0;36mAPIError.raise_for_response\u001b[1;34m(cls, response)\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m600\u001b[39m:\n\u001b[1;32m--> 107\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(status_code, response_json, response)\n",
      "\u001b[1;31mServerError\u001b[0m: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}"
     ]
    }
   ],
   "source": [
    "# ==== 基本依赖 ====\n",
    "import os, re, math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from google import genai\n",
    "\n",
    "# ==== 环境 ====\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY   = os.getenv(\"OPENAI_API_KEY\")\n",
    "DEEPSEEK_API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")  # 仅后续鲁棒性用，不在本脚本里跑\n",
    "# GEMINI_API_KEY 由 genai.Client() 自行从环境读取\n",
    "\n",
    "# ==== 模型与客户端 ====\n",
    "# GPT 主力评分（快）：gpt-4o-mini\n",
    "gpt_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "GPT_MODEL  = \"gpt-4o-mini\"\n",
    "\n",
    "# Gemini-Pro（抽检）\n",
    "gem_client = genai.Client()\n",
    "GEM_MODEL  = \"gemini-2.5-flash\"\n",
    "\n",
    "# ClinicalBERT（基线）\n",
    "BERT_NAME  = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(BERT_NAME)\n",
    "bert_model = AutoModel.from_pretrained(BERT_NAME)\n",
    "bert_model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bert_model.to(device)\n",
    "\n",
    "# ==== 读取底表 ====\n",
    "# 需要列：Original, Synthetic, Transform_Type, Specialty, Source\n",
    "pairs = pd.read_csv(\"synthetic_reports.csv\").reset_index().rename(columns={\"index\":\"pair_id\"})\n",
    "\n",
    "# === 关键改动：为“同一原始报告”的5条建立 group_id ===\n",
    "# 用 Original 分组，保持出现顺序（sort=False），同一原文的5条会得到同一个 group_id\n",
    "pairs[\"group_id\"] = pairs.groupby(\"Original\", sort=False).ngroup()\n",
    "\n",
    "\n",
    "# ==== 抽检比例（一个数字即可）====\n",
    "SUBSET_FRAC = 0.2  # 20%~30% 之间自己改\n",
    "\n",
    "all_groups = pd.Index(pairs[\"group_id\"].unique())\n",
    "\n",
    "# 采样到的 group_id（整组抽）\n",
    "sampled_groups = (all_groups.to_series()\n",
    "                  .sample(frac=SUBSET_FRAC, random_state=42)\n",
    "                  .sort_values())  # 组ID按顺序，方便后续查看\n",
    "\n",
    "# === 得到 subset / rest，并按 pair_id 升序排列 ===\n",
    "subset = (pairs[pairs[\"group_id\"].isin(sampled_groups)]\n",
    "          .sort_values(\"pair_id\")\n",
    "          .reset_index(drop=True))\n",
    "\n",
    "rest   = (pairs[~pairs[\"group_id\"].isin(sampled_groups)]\n",
    "          .sort_values(\"pair_id\")\n",
    "          .reset_index(drop=True))\n",
    "\n",
    "print(f\"总组数: {pairs['group_id'].nunique()} | 抽检组数: {subset['group_id'].nunique()} | \"\n",
    "      f\"subset条数: {len(subset)} | rest条数: {len(rest)}\")\n",
    "\n",
    "# ==== 通用：提取分数 ====\n",
    "num_pattern = re.compile(r\"(?<!\\d)(\\d+(?:\\.\\d+)?)(?!\\d)\")  # 抓 12 或 12.3\n",
    "\n",
    "def extract_score(text: str):\n",
    "    m = num_pattern.search(text)\n",
    "    if not m: \n",
    "        return None\n",
    "    val = float(m.group(1))\n",
    "    # 保守截断 0~10\n",
    "    return max(0.0, min(10.0, val))\n",
    "\n",
    "# ==== 打分提示词（无 JSON，要求输出“纯数字0-10”）====\n",
    "SCORE_PROMPT = \"\"\"You are a medical report evaluator.\n",
    "Compare clinical meaning only (findings, laterality, devices, measurements, diagnoses).\n",
    "Score from 0 to 10 where 10 = identical clinical meaning and 0 = contradictory/irrelevant.\n",
    "\n",
    "Scoring instructions:\n",
    "Assign a similarity score from 0.0 to 10.0 (one decimal place):\n",
    "10.0: Completely identical in all clinically meaningful aspects.\n",
    "8-9.9: Only very minor differences (e.g., \"small\" vs. \"mild\"; equivalent negative findings; different but clinically irrelevant wording).\n",
    "6-7.9: Noticeable but not clinically significant differences (e.g., \"small\" vs. \"moderate\" effusion; more detail in one report, but the overall meaning is similar).\n",
    "3-5.9: Clinically significant but not directly contradictory (e.g., one report notes a finding the other omits; or laterality mismatch, but not a direct contradiction).\n",
    "0-2.9: Reports are clinically contradictory (e.g., one says \"definite pneumonia,\" the other says \"no pneumonia\"; or one says \"fracture present,\" the other \"no fracture\").\n",
    "Return ONLY a single number (0-10, one decimal). No words.\n",
    "\n",
    "Report A (original):\n",
    "{A}\n",
    "\n",
    "Report B (candidate):\n",
    "{B}\n",
    "\"\"\"\n",
    "\n",
    "# ==== GPT-4o-mini 打分 ====\n",
    "def score_gpt(a: str, b: str) -> float:\n",
    "    prompt = SCORE_PROMPT.format(A=a, B=b)\n",
    "    resp = gpt_client.chat.completions.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages=[\n",
    "            {\"role\":\"system\",\"content\":\"You are a precise clinical text evaluator.\"},\n",
    "            {\"role\":\"user\",\"content\":prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        stream=False\n",
    "    )\n",
    "    out = resp.choices[0].message.content.strip()\n",
    "    return extract_score(out)\n",
    "\n",
    "# ==== Gemini-Pro 打分 ====\n",
    "def score_gemini(a: str, b: str) -> float:\n",
    "    prompt = SCORE_PROMPT.format(A=a, B=b)\n",
    "    response = gem_client.models.generate_content(model=GEM_MODEL, contents=prompt)\n",
    "    out = (response.text or \"\").strip()\n",
    "    return extract_score(out)\n",
    "\n",
    "# ==== ClinicalBERT 余弦（映射到 0-10）====\n",
    "def cls_embedding(text: str) -> torch.Tensor:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "        # 取 [CLS]\n",
    "        emb = outputs.last_hidden_state[:,0,:]   # [1, hidden]\n",
    "    return emb.squeeze(0).cpu()  # [hidden]\n",
    "\n",
    "def score_bert(a: str, b: str) -> float:\n",
    "    e1 = cls_embedding(a)\n",
    "    e2 = cls_embedding(b)\n",
    "    cos = cosine_similarity(e1, e2, dim=0).item()      # [-1, 1]\n",
    "    score = (cos + 1.0) / 2.0 * 10.0                   # → [0, 10]\n",
    "    score = max(0.0, min(10.0, score))\n",
    "    return round(score, 2)\n",
    "\n",
    "# ==== 极简进度显示 ====\n",
    "def progress(i, n, prefix=\"Progress\"):\n",
    "    pct = int((i+1)*100/n)\n",
    "    print(f\"\\r{prefix}: {pct}%\", end=\"\", flush=True)\n",
    "\n",
    "# =========================\n",
    "# ① 抽检：Gemini + GPT + BERT\n",
    "# =========================\n",
    "sub_rows = []\n",
    "N = len(subset)\n",
    "for i, r in enumerate(subset.itertuples(index=False)):\n",
    "    a = r.Original\n",
    "    b = r.Synthetic\n",
    "    s_gpt    = score_gpt(a, b)\n",
    "    s_gemini = score_gemini(a, b)\n",
    "    s_bert   = score_bert(a, b)\n",
    "    sub_rows.append({\n",
    "        \"pair_id\": r.pair_id,\n",
    "        \"Original\": a,\n",
    "        \"Synthetic\": b,\n",
    "        \"Transform_Type\": r.Transform_Type,\n",
    "        \"Specialty\": r.Specialty,\n",
    "        \"Source\": r.Source,\n",
    "        \"score_gpt4omini\": s_gpt,\n",
    "        \"score_gemini\": s_gemini,\n",
    "        \"score_clinicalbert\": s_bert\n",
    "    })\n",
    "    progress(i, N, prefix=\"Subset scoring\")\n",
    "\n",
    "print()  # 换行\n",
    "subset_scored = pd.DataFrame(sub_rows)\n",
    "subset_scored.to_csv(\"subset_scored.csv\", index=False)\n",
    "print(f\"✅ subset_scored.csv 保存完成：{len(subset_scored)}\")\n",
    "\n",
    "# =========================\n",
    "# ② 其余：GPT + BERT\n",
    "# =========================\n",
    "rest_rows = []\n",
    "N = len(rest)\n",
    "for i, r in enumerate(rest.itertuples(index=False)):\n",
    "    a = r.Original\n",
    "    b = r.Synthetic\n",
    "    s_gpt  = score_gpt(a, b)\n",
    "    s_bert = score_bert(a, b)\n",
    "    rest_rows.append({\n",
    "        \"pair_id\": r.pair_id,\n",
    "        \"Original\": a,\n",
    "        \"Synthetic\": b,\n",
    "        \"Transform_Type\": r.Transform_Type,\n",
    "        \"Specialty\": r.Specialty,\n",
    "        \"Source\": r.Source,\n",
    "        \"score_gpt4omini\": s_gpt,\n",
    "        \"score_clinicalbert\": s_bert\n",
    "    })\n",
    "    progress(i, N, prefix=\"Rest scoring\")\n",
    "\n",
    "print()\n",
    "rest_scored = pd.DataFrame(rest_rows)\n",
    "rest_scored.to_csv(\"rest_scored.csv\", index=False)\n",
    "print(f\"✅ rest_scored.csv 保存完成：{len(rest_scored)}\")\n",
    "\n",
    "# ==（可选）检查一下列名 ==\n",
    "print(subset_scored.columns.tolist())\n",
    "print(rest_scored.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1068102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存 subset_scored_partial.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(sub_rows).to_csv(\"subset_scored_partial.csv\", index=False)\n",
    "print(\"已保存 subset_scored_partial.csv\")\n",
    "subset.to_csv(\"subset_pairs.csv\", index=False)\n",
    "rest.to_csv(\"rest_pairs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b756b424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "待续跑条数: 1112\n",
      "Resume subset scoring: 84%"
     ]
    },
    {
     "ename": "ServerError",
     "evalue": "503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mServerError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m a, b \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mOriginal, r\u001b[38;5;241m.\u001b[39mSynthetic\n\u001b[0;32m     17\u001b[0m s_gpt    \u001b[38;5;241m=\u001b[39m score_gpt(a, b)\n\u001b[1;32m---> 18\u001b[0m s_gemini \u001b[38;5;241m=\u001b[39m score_gemini(a, b)\n\u001b[0;32m     19\u001b[0m s_bert   \u001b[38;5;241m=\u001b[39m score_bert(a, b)           \u001b[38;5;66;03m# 内部已 round(…, 2) 更好\u001b[39;00m\n\u001b[0;32m     21\u001b[0m more_rows\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpair_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: r\u001b[38;5;241m.\u001b[39mpair_id,\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal\u001b[39m\u001b[38;5;124m\"\u001b[39m: a,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_clinicalbert\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mround\u001b[39m(s_bert, \u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m     31\u001b[0m })\n",
      "Cell \u001b[1;32mIn[1], line 115\u001b[0m, in \u001b[0;36mscore_gemini\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore_gemini\u001b[39m(a: \u001b[38;5;28mstr\u001b[39m, b: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m    114\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m SCORE_PROMPT\u001b[38;5;241m.\u001b[39mformat(A\u001b[38;5;241m=\u001b[39ma, B\u001b[38;5;241m=\u001b[39mb)\n\u001b[1;32m--> 115\u001b[0m     response \u001b[38;5;241m=\u001b[39m gem_client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content(model\u001b[38;5;241m=\u001b[39mGEM_MODEL, contents\u001b[38;5;241m=\u001b[39mprompt)\n\u001b[0;32m    116\u001b[0m     out \u001b[38;5;241m=\u001b[39m (response\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m extract_score(out)\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\google\\genai\\models.py:6138\u001b[0m, in \u001b[0;36mModels.generate_content\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   6136\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   6137\u001b[0m   i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 6138\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content(\n\u001b[0;32m   6139\u001b[0m       model\u001b[38;5;241m=\u001b[39mmodel, contents\u001b[38;5;241m=\u001b[39mcontents, config\u001b[38;5;241m=\u001b[39mparsed_config\n\u001b[0;32m   6140\u001b[0m   )\n\u001b[0;32m   6141\u001b[0m   logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAFC remote call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is done.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   6142\u001b[0m   remaining_remote_calls_afc \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\google\\genai\\models.py:4959\u001b[0m, in \u001b[0;36mModels._generate_content\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   4956\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mconvert_to_dict(request_dict)\n\u001b[0;32m   4957\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mencode_unserializable_types(request_dict)\n\u001b[1;32m-> 4959\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m   4960\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m, path, request_dict, http_options\n\u001b[0;32m   4961\u001b[0m )\n\u001b[0;32m   4963\u001b[0m response_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;28;01melse\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mbody)\n\u001b[0;32m   4965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mvertexai:\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\google\\genai\\_api_client.py:1266\u001b[0m, in \u001b[0;36mBaseApiClient.request\u001b[1;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m   1257\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1258\u001b[0m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1261\u001b[0m     http_options: Optional[HttpOptionsOrDict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SdkHttpResponse:\n\u001b[0;32m   1263\u001b[0m   http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[0;32m   1264\u001b[0m       http_method, path, request_dict, http_options\n\u001b[0;32m   1265\u001b[0m   )\n\u001b[1;32m-> 1266\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(http_request, http_options, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1267\u001b[0m   response_body \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1268\u001b[0m       response\u001b[38;5;241m.\u001b[39mresponse_stream[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mresponse_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1269\u001b[0m   )\n\u001b[0;32m   1270\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders, body\u001b[38;5;241m=\u001b[39mresponse_body)\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\google\\genai\\_api_client.py:1086\u001b[0m, in \u001b[0;36mBaseApiClient._request\u001b[1;34m(self, http_request, http_options, stream)\u001b[0m\n\u001b[0;32m   1083\u001b[0m     retry \u001b[38;5;241m=\u001b[39m tenacity\u001b[38;5;241m.\u001b[39mRetrying(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mretry_kwargs)\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[1;32m-> 1086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_once, http_request, stream)\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    323\u001b[0m     retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 325\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m retry_exc\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait:\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\google\\genai\\_api_client.py:1063\u001b[0m, in \u001b[0;36mBaseApiClient._request_once\u001b[1;34m(self, http_request, stream)\u001b[0m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1056\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpx_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m   1057\u001b[0m       method\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m   1058\u001b[0m       url\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1061\u001b[0m       timeout\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[0;32m   1062\u001b[0m   )\n\u001b[1;32m-> 1063\u001b[0m   errors\u001b[38;5;241m.\u001b[39mAPIError\u001b[38;5;241m.\u001b[39mraise_for_response(response)\n\u001b[0;32m   1064\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[0;32m   1065\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[0;32m   1066\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\google\\genai\\errors.py:107\u001b[0m, in \u001b[0;36mAPIError.raise_for_response\u001b[1;34m(cls, response)\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m600\u001b[39m:\n\u001b[1;32m--> 107\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(status_code, response_json, response)\n",
      "\u001b[1;31mServerError\u001b[0m: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读入抽检全集 & 已完成部分\n",
    "subset_all = pd.read_csv(\"subset_pairs.csv\")                 # 抽检全集（1605 条）\n",
    "done_df    = pd.read_csv(\"subset_scored_partial.csv\")        # 已完成（约30%）\n",
    "\n",
    "done_ids = set(done_df[\"pair_id\"])\n",
    "todo = subset_all[~subset_all[\"pair_id\"].isin(done_ids)].copy()\n",
    "\n",
    "print(f\"待续跑条数: {len(todo)}\")\n",
    "\n",
    "# 继续跑剩余\n",
    "more_rows = []\n",
    "N = len(todo)\n",
    "for i, r in enumerate(todo.itertuples(index=False)):\n",
    "    a, b = r.Original, r.Synthetic\n",
    "    s_gpt    = score_gpt(a, b)\n",
    "    s_gemini = score_gemini(a, b)\n",
    "    s_bert   = score_bert(a, b)           # 内部已 round(…, 2) 更好\n",
    "\n",
    "    more_rows.append({\n",
    "        \"pair_id\": r.pair_id,\n",
    "        \"Original\": a,\n",
    "        \"Synthetic\": b,\n",
    "        \"Transform_Type\": r.Transform_Type,\n",
    "        \"Specialty\": r.Specialty,\n",
    "        \"Source\": r.Source,\n",
    "        \"score_gpt4omini\": s_gpt,\n",
    "        \"score_gemini\": s_gemini,\n",
    "        \"score_clinicalbert\": round(s_bert, 2),\n",
    "    })\n",
    "\n",
    "    # 简单进度\n",
    "    pct = int((i+1)*100/N)\n",
    "    print(f\"\\rResume subset scoring: {pct}%\", end=\"\", flush=True)\n",
    "print()\n",
    "\n",
    "# 合并 → 去重（以 pair_id 为准）→ 按 pair_id 排序 → 保存最终 subset\n",
    "subset_scored = pd.concat([done_df, pd.DataFrame(more_rows)], ignore_index=True)\n",
    "subset_scored = subset_scored.sort_values(\"pair_id\").drop_duplicates(\"pair_id\", keep=\"last\")\n",
    "subset_scored.to_csv(\"subset_scored.csv\", index=False)\n",
    "print(f\"✅ subset_scored.csv 完成：{len(subset_scored)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "243dee8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 保存 subset_scored_partial2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 把内存中的 more_rows 固化为第二个分片\n",
    "pd.DataFrame(more_rows).to_csv(\"subset_scored_partial2.csv\", index=False)\n",
    "print(\"✔ 保存 subset_scored_partial2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9979eb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最后待跑条数: 169\n",
      "Resume last 16%: 100%\n",
      "✅ subset_scored.csv 完成：1605 条\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读入抽检全集（整组抽样得到的全集）\n",
    "subset_all = pd.read_csv(\"subset_pairs.csv\")  # 含 pair_id, Original, Synthetic, Transform_Type, Specialty, Source\n",
    "\n",
    "# 已完成的两个分片\n",
    "p1 = pd.read_csv(\"subset_scored_partial.csv\")   # 第一段 ~30%\n",
    "p2 = pd.read_csv(\"subset_scored_partial2.csv\")  # 第二段 ~84%（相对于“待续跑集”）\n",
    "\n",
    "# 计算还未评分的 pair_id\n",
    "done_ids = set(p1[\"pair_id\"]) | set(p2[\"pair_id\"])\n",
    "todo = subset_all[~subset_all[\"pair_id\"].isin(done_ids)].copy()\n",
    "print(\"最后待跑条数:\", len(todo))\n",
    "\n",
    "# 跑最后 16%\n",
    "final_rows = []\n",
    "N = len(todo)\n",
    "for i, r in enumerate(todo.itertuples(index=False)):\n",
    "    a, b = r.Original, r.Synthetic\n",
    "    s_gpt    = score_gpt(a, b)\n",
    "    s_gemini = score_gemini(a, b)\n",
    "    s_bert   = score_bert(a, b)\n",
    "    final_rows.append({\n",
    "        \"pair_id\": r.pair_id,\n",
    "        \"Original\": a,\n",
    "        \"Synthetic\": b,\n",
    "        \"Transform_Type\": r.Transform_Type,\n",
    "        \"Specialty\": r.Specialty,\n",
    "        \"Source\": r.Source,\n",
    "        \"score_gpt4omini\": s_gpt,\n",
    "        \"score_gemini\": s_gemini,\n",
    "        \"score_clinicalbert\": round(s_bert, 2),\n",
    "    })\n",
    "    # 简单进度\n",
    "    pct = int((i+1)*100/N) if N else 100\n",
    "    print(f\"\\rResume last 16%: {pct}%\", end=\"\", flush=True)\n",
    "print()\n",
    "\n",
    "# 合并三个分片 → 去重（pair_id）→ 排序 → 保存最终 subset\n",
    "p3 = pd.DataFrame(final_rows)\n",
    "subset_scored = pd.concat([p1, p2, p3], ignore_index=True)\n",
    "subset_scored = subset_scored.sort_values(\"pair_id\").drop_duplicates(\"pair_id\", keep=\"last\")\n",
    "\n",
    "#（可选）所有分数统一保留两位\n",
    "for col in [\"score_gpt4omini\", \"score_gemini\", \"score_clinicalbert\"]:\n",
    "    if col in subset_scored:\n",
    "        subset_scored[col] = subset_scored[col].round(2)\n",
    "\n",
    "subset_scored.to_csv(\"subset_scored.csv\", index=False)\n",
    "print(f\"✅ subset_scored.csv 完成：{len(subset_scored)} 条\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90f832cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rest scoring: 100%\n",
      "✅ rest_scored.csv 保存完成：6420\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# ② 其余：GPT + BERT\n",
    "# =========================\n",
    "rest_rows = []\n",
    "N = len(rest)\n",
    "for i, r in enumerate(rest.itertuples(index=False)):\n",
    "    a = r.Original\n",
    "    b = r.Synthetic\n",
    "    s_gpt  = score_gpt(a, b)\n",
    "    s_bert = score_bert(a, b)\n",
    "    rest_rows.append({\n",
    "        \"pair_id\": r.pair_id,\n",
    "        \"Original\": a,\n",
    "        \"Synthetic\": b,\n",
    "        \"Transform_Type\": r.Transform_Type,\n",
    "        \"Specialty\": r.Specialty,\n",
    "        \"Source\": r.Source,\n",
    "        \"score_gpt4omini\": s_gpt,\n",
    "        \"score_clinicalbert\": s_bert\n",
    "    })\n",
    "    progress(i, N, prefix=\"Rest scoring\")\n",
    "\n",
    "print()\n",
    "rest_scored = pd.DataFrame(rest_rows)\n",
    "rest_scored.to_csv(\"rest_scored.csv\", index=False)\n",
    "print(f\"✅ rest_scored.csv 保存完成：{len(rest_scored)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01401c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek 抽样：组数 40/1605  → 样本对数 200\n",
      "DeepSeek scoring: 100%\n",
      "✅ deepseek_scored.csv 保存完成：200 条\n"
     ]
    }
   ],
   "source": [
    "# deepseek 抽样\n",
    "import os, re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ================= 配置 =================\n",
    "DS_MAX_PAIRS   = 200               # 最多抽样 200 对（≈40 组）\n",
    "DEEPSEEK_KEY   = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "assert DEEPSEEK_KEY, \"请在环境变量中设置 DEEPSEEK_API_KEY\"\n",
    "ds_client      = OpenAI(api_key=DEEPSEEK_KEY, base_url=\"https://api.deepseek.com\")\n",
    "DS_MODEL       = \"deepseek-reasoner\"\n",
    "SUBSET_PATH    = \"subset_pairs.csv\"\n",
    "REST_PATH      = \"rest_pairs.csv\"\n",
    "ALL_PATH       = \"synthetic_reports.csv\"   # 兜底\n",
    "\n",
    "# ================ 读取并准备全集（带 pair_id / group_id） =================\n",
    "if os.path.exists(SUBSET_PATH) and os.path.exists(REST_PATH):\n",
    "    df_sub = pd.read_csv(SUBSET_PATH)\n",
    "    df_rst = pd.read_csv(REST_PATH)\n",
    "    df_all = pd.concat([df_sub, df_rst], ignore_index=True)\n",
    "else:\n",
    "    df_all = pd.read_csv(ALL_PATH)\n",
    "    df_all = df_all.reset_index().rename(columns={\"index\":\"pair_id\"})\n",
    "\n",
    "# 若缺少 group_id，则根据 Original 生成（同一原文的5条一个组）\n",
    "if \"group_id\" not in df_all.columns:\n",
    "    df_all[\"group_id\"] = df_all.groupby(\"Original\", sort=False).ngroup()\n",
    "\n",
    "# 统一必要列顺序\n",
    "base_cols = [\"pair_id\",\"group_id\",\"Original\",\"Synthetic\",\"Transform_Type\",\"Specialty\",\"Source\"]\n",
    "df_all = df_all[base_cols].sort_values(\"pair_id\").reset_index(drop=True)\n",
    "\n",
    "# ================ 组抽样（整组 5 条一起抽） =================\n",
    "n_groups_total = df_all[\"group_id\"].nunique()\n",
    "n_groups_need  = min(DS_MAX_PAIRS // 5, n_groups_total)\n",
    "sampled_groups = (pd.Series(df_all[\"group_id\"].unique())\n",
    "                    .sample(n=n_groups_need, random_state=123)\n",
    "                    .sort_values())\n",
    "\n",
    "sample_df = (df_all[df_all[\"group_id\"].isin(sampled_groups)]\n",
    "             .sort_values(\"pair_id\")\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "# 截断到 DS_MAX_PAIRS（防止不是5的倍数时多出来）\n",
    "if len(sample_df) > DS_MAX_PAIRS:\n",
    "    sample_df = sample_df.iloc[:DS_MAX_PAIRS].copy()\n",
    "\n",
    "print(f\"DeepSeek 抽样：组数 {n_groups_need}/{n_groups_total}  → 样本对数 {len(sample_df)}\")\n",
    "\n",
    "# ================ 评分：DeepSeek =================\n",
    "num_pattern = re.compile(r\"(?<!\\d)(\\d+(?:\\.\\d+)?)(?!\\d)\")\n",
    "\n",
    "SCORE_PROMPT = \"\"\"You are a medical report evaluator.\n",
    "Compare clinical meaning only (findings, laterality, devices, measurements, diagnoses).\n",
    "Score from 0 to 10 where 10 = identical clinical meaning and 0 = contradictory/irrelevant.\n",
    "\n",
    "Scoring instructions:\n",
    "Assign a similarity score from 0.0 to 10.0 (one decimal place):\n",
    "10.0: Completely identical in all clinically meaningful aspects.\n",
    "8-9.9: Only very minor differences (e.g., \"small\" vs. \"mild\"; equivalent negative findings; different but clinically irrelevant wording).\n",
    "6-7.9: Noticeable but not clinically significant differences (e.g., \"small\" vs. \"moderate\" effusion; more detail in one report, but the overall meaning is similar).\n",
    "3-5.9: Clinically significant but not directly contradictory (e.g., one report notes a finding the other omits; or laterality mismatch, but not a direct contradiction).\n",
    "0-2.9: Reports are clinically contradictory (e.g., one says \"definite pneumonia,\" the other says \"no pneumonia\"; or one says \"fracture present,\" the other \"no fracture\").\n",
    "Return ONLY a single number (0-10, one decimal). No words.\n",
    "\n",
    "Report A (original):\n",
    "{A}\n",
    "\n",
    "Report B (candidate):\n",
    "{B}\n",
    "\"\"\"\n",
    "\n",
    "def extract_score(text: str):\n",
    "    m = num_pattern.search(text or \"\")\n",
    "    if not m: \n",
    "        return None\n",
    "    v = float(m.group(1))\n",
    "    # 保守截断 0~10 并保留两位\n",
    "    return round(max(0.0, min(10.0, v)), 2)\n",
    "\n",
    "def score_deepseek(a: str, b: str) -> float:\n",
    "    prompt = SCORE_PROMPT.format(A=a, B=b)\n",
    "    resp = ds_client.chat.completions.create(\n",
    "        model=DS_MODEL,\n",
    "        messages=[\n",
    "            {\"role\":\"system\",\"content\":\"You are a precise clinical text evaluator.\"},\n",
    "            {\"role\":\"user\",\"content\":prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        stream=False\n",
    "    )\n",
    "    out = resp.choices[0].message.content.strip()\n",
    "    return extract_score(out)\n",
    "\n",
    "# 进度\n",
    "def progress(i, n, prefix=\"DeepSeek scoring\"):\n",
    "    pct = int((i+1)*100/n)\n",
    "    print(f\"\\r{prefix}: {pct}%\", end=\"\", flush=True)\n",
    "\n",
    "rows = []\n",
    "N = len(sample_df)\n",
    "for i, r in enumerate(sample_df.itertuples(index=False)):\n",
    "    s = score_deepseek(r.Original, r.Synthetic)\n",
    "    rows.append({\n",
    "        \"pair_id\": r.pair_id,\n",
    "        \"Original\": r.Original,\n",
    "        \"Synthetic\": r.Synthetic,\n",
    "        \"Transform_Type\": r.Transform_Type,\n",
    "        \"Specialty\": r.Specialty,\n",
    "        \"Source\": r.Source,\n",
    "        \"score_deepseek\": s\n",
    "    })\n",
    "    progress(i, N)\n",
    "\n",
    "print()  # 换行\n",
    "\n",
    "deepseek_scored = pd.DataFrame(rows).sort_values(\"pair_id\")\n",
    "deepseek_scored.to_csv(\"deepseek_scored.csv\", index=False)\n",
    "print(f\"✅ deepseek_scored.csv 保存完成：{len(deepseek_scored)} 条\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
